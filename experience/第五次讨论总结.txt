王子健：
===指导内容====
尝试将写的代码变成api接口部署到服务；学习一下bs模型；web of science中的JCR数据进行寻找，拿到其中分类体系；
调研一下中国知网期刊是否有分类体系，找一下《中国图书资料分类法》电子文件；

===研究进度===
完成了简单的基于字符串算法匹配，实现论文相似度的代码，完善了其中的功能可以使用停用词，去除一些无用字符

===问题以及调整方式===
es安装问题和没有熟练虚拟机中的语法：进度加快
字符串，list，元组，字典格式不统一，用法不一样，使得在函数中使用限制很大，格式太乱使得无法进行筛出无用字符，停用词等：学习转换方式与基础知识，对于格式进行整改使得预处理的功能得以实现

===具体问题===
1.https://www.cnblogs.com/dw3306/p/14037808.html(es安装报错问题，一些解决方法)
2.https://www.cnblogs.com/tyhj-zxp/p/13166671.html(kibana安装报错问题)
3.字符串，元组，list，dict转换
# 数组arr转字符串str
str = ','.join(str(i) for i in arr)(括号内可以直接放元组名)
print('str:',str)
# 字符串str转列表list1
list1 = str.split(',')
# 列表list1转列表list2
list2 = []
for j in list1:
list2.append(float(j))
# 列表list2转arr1
arr1 = np.array(list2)
print('arr1:',arr1)
#字典转为字符串，返回：<type 'str'> {'age': 7, 'name': 'Zara', 'class': 'First'}
print(type(str(dict)), str(dict))
#字典可以转为元组，返回：('age', 'name', 'class')
print(tuple(dict))
#字典转为列表，返回：['age', 'name', 'class']
print(list(dict))
#字典转为列表
print(dict.values)

王亚可：
===指导内容====
	·继续尝试在服务器上部署任务；
	·练习拿到springer的英文期刊分类爬取；
	·词库的关系可以更复杂一点；
	·arangodb中的数据尝试用图的形式展示。
===研究进度===
	·已经初步的根据词库生成了三元组，可以让服务器在后期进行长时间的计算；
	·根据词库，写了简单的一套代码，依据字符匹配，生成了三元组，并存入arangodb中。
	
===问题以及调整方式===
	·服务器上部署服务还没成功	：还是要攻克，多尝试

===具体问题===

arangodb简单实例：
https://www.cnblogs.com/minglex/p/9383849.html；

arangodb 导入.csv文件：
https://blog.csdn.net/u011119840/article/details/87856235


python抽取形成三元组：
https://blog.csdn.net/weixin_44398527/article/details/114107029



薛冠文：
===指导内容====
-运行Semantic-Textual-Similarity-master文件，了解模型构成
-将链接下的左侧目录门类进行爬取
===研究进度===
-重新按照层级关系的数据结构创建了新的json文件目录
-打开运行了master文件
-学习预处理的停用词、stem词根变化和时态变化等
===问题以及调整方式===
论文匹配打标签没有成功
预处理相关内容没掌握
调整方式：多了解模型结构，加快数据爬取的进度
将nltk包引用
阅读“基于表示学习的论文分类方法研究”，“核心期刊评价的分学科方法解析”等文章
实现爬虫把sci的类目爬取下来

===具体问题===
目录门类链接
https://www.sciencedirect.com/browse/journals-and-books?subject=mathematics